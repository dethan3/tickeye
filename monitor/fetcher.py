import akshare as ak
import pandas as pd
import logging
import sys
from typing import List, Optional, Dict, Any
import time
from datetime import datetime

# Python ç‰ˆæœ¬æ£€æŸ¥ (AKShare è¦æ±‚ 3.9+)
if sys.version_info < (3, 9):
    raise RuntimeError("TickEye requires Python 3.9 or higher (AKShare requirement)")

logger = logging.getLogger(__name__)

# ç®€åŒ–çš„ç¼“å­˜é…ç½®
CACHE_EXPIRE_TIME = 120  # 2åˆ†é’Ÿï¼Œé€‚åˆäº¤æ˜“æ—¶æ®µçš„æ•°æ®å˜åŒ–


class SimpleFundDataFetcher:
    """ç®€åŒ–ç‰ˆåŸºé‡‘æ•°æ®è·å–å™¨ï¼Œéµå¾ª AKShare çš„ç®€å•å“²å­¦"""
    
    def __init__(self):
        self._last_fetch_time = {}  # åˆ†ç±»å‹çš„æœ€åè·å–æ—¶é—´
        self._cache = {}  # åˆ†ç±»å‹çš„ç¼“å­˜æ•°æ®
    
    def _is_cache_valid(self, cache_type: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šç±»å‹çš„ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_type not in self._last_fetch_time:
            return False
        return time.time() - self._last_fetch_time[cache_type] < CACHE_EXPIRE_TIME
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """åŸºæœ¬çš„æ•°æ®æ¸…ç†ï¼Œç§»é™¤æ— æ•ˆè¡Œ"""
        if df is None or df.empty:
            return df
        
        # ç§»é™¤åŸºé‡‘ä»£ç ä¸ºç©ºçš„è¡Œ
        if 'åŸºé‡‘ä»£ç ' in df.columns:
            df = df.dropna(subset=['åŸºé‡‘ä»£ç '])
            df = df[df['åŸºé‡‘ä»£ç '].str.len() == 6]  # åŸºé‡‘ä»£ç åº”è¯¥æ˜¯6ä½
        
        return df.reset_index(drop=True)
    
    def get_open_fund_data(self, force_refresh: bool = False) -> Optional[pd.DataFrame]:
        """
        è·å–å¼€æ”¾å¼åŸºé‡‘æ•°æ® - ç®€åŒ–ç‰ˆ
        
        Args:
            force_refresh: å¼ºåˆ¶åˆ·æ–°æ•°æ®
            
        Returns:
            pd.DataFrame: åŸºé‡‘æ•°æ®ï¼Œä½¿ç”¨ AKShare çš„åŸå§‹åˆ—å
        """
        cache_key = 'open_fund'
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and self._is_cache_valid(cache_key):
            logger.debug("ä½¿ç”¨ç¼“å­˜çš„å¼€æ”¾å¼åŸºé‡‘æ•°æ®")
            return self._cache.get(cache_key)
        
        try:
            logger.info("æ­£åœ¨è·å–å¼€æ”¾å¼åŸºé‡‘æ•°æ®...")
            df = ak.fund_open_fund_info_em()
            
            if df is not None and not df.empty:
                df = self._clean_data(df)
                self._cache[cache_key] = df
                self._last_fetch_time[cache_key] = time.time()
                logger.info(f"æˆåŠŸè·å– {len(df)} åªå¼€æ”¾å¼åŸºé‡‘æ•°æ®")
                return df
            else:
                logger.warning("è·å–çš„å¼€æ”¾å¼åŸºé‡‘æ•°æ®ä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"è·å–å¼€æ”¾å¼åŸºé‡‘æ•°æ®å¤±è´¥: {e}")
            # è¿”å›ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡ç”¨
            cached_data = self._cache.get(cache_key)
            if cached_data is not None:
                logger.warning("APIå¤±è´¥ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
                return cached_data
            return None
    
    def get_index_fund_data(self, force_refresh: bool = False) -> Optional[pd.DataFrame]:
        """
        è·å–æŒ‡æ•°åŸºé‡‘/ETFæ•°æ® - ç®€åŒ–ç‰ˆ
        
        Args:
            force_refresh: å¼ºåˆ¶åˆ·æ–°æ•°æ®
            
        Returns:
            pd.DataFrame: åŸºé‡‘æ•°æ®ï¼Œä½¿ç”¨ AKShare çš„åŸå§‹åˆ—å
        """
        cache_key = 'index_fund'
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and self._is_cache_valid(cache_key):
            logger.debug("ä½¿ç”¨ç¼“å­˜çš„æŒ‡æ•°åŸºé‡‘æ•°æ®")
            return self._cache.get(cache_key)
        
        try:
            logger.info("æ­£åœ¨è·å–æŒ‡æ•°åŸºé‡‘æ•°æ®...")
            df = ak.fund_etf_fund_info_em()
            
            if df is not None and not df.empty:
                df = self._clean_data(df)
                self._cache[cache_key] = df
                self._last_fetch_time[cache_key] = time.time()
                logger.info(f"æˆåŠŸè·å– {len(df)} åªæŒ‡æ•°åŸºé‡‘æ•°æ®")
                return df
            else:
                logger.warning("è·å–çš„æŒ‡æ•°åŸºé‡‘æ•°æ®ä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"è·å–æŒ‡æ•°åŸºé‡‘æ•°æ®å¤±è´¥: {e}")
            # è¿”å›ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡ç”¨
            cached_data = self._cache.get(cache_key)
            if cached_data is not None:
                logger.warning("APIå¤±è´¥ï¼Œè¿”å›ç¼“å­˜æ•°æ®")
                return cached_data
            return None
    
    def get_specific_funds(self, codes: List[str], fund_type: str = 'open') -> Optional[pd.DataFrame]:
        """
        è·å–æŒ‡å®šåŸºé‡‘ä»£ç çš„æ•°æ® - ç®€åŒ–ç‰ˆ
        
        Args:
            codes: åŸºé‡‘ä»£ç åˆ—è¡¨
            fund_type: åŸºé‡‘ç±»å‹ ('open' æˆ– 'index')
            
        Returns:
            pd.DataFrame: ç­›é€‰åçš„åŸºé‡‘æ•°æ®
        """
        if not codes:
            return None
        
        # ç›´æ¥è·å–å…¨é‡æ•°æ®å¹¶ç­›é€‰ (AKShare çš„ç®€å•æ–¹å¼)
        if fund_type == 'open':
            all_data = self.get_open_fund_data()
        else:
            all_data = self.get_index_fund_data()
        
        if all_data is None or all_data.empty:
            return None
        
        # ç­›é€‰æŒ‡å®šçš„åŸºé‡‘ä»£ç 
        if 'åŸºé‡‘ä»£ç ' in all_data.columns:
            filtered_data = all_data[all_data['åŸºé‡‘ä»£ç '].isin(codes)]
            logger.info(f"ç­›é€‰å‡º {len(filtered_data)}/{len(codes)} åªåŸºé‡‘")
            return filtered_data
        else:
            logger.error("æ•°æ®ä¸­ç¼ºå°‘'åŸºé‡‘ä»£ç 'åˆ—")
            return None
    
    def get_funds_by_config(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """
        æ ¹æ®é…ç½®è·å–åŸºé‡‘æ•°æ® - ç®€åŒ–ç‰ˆ
        
        Args:
            config: é…ç½®å­—å…¸
            
        Returns:
            pd.DataFrame: åˆå¹¶åçš„åŸºé‡‘æ•°æ®
        """
        if not config or 'rules' not in config:
            return None
        
        all_codes = set()
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦ç›‘æ§çš„åŸºé‡‘ä»£ç 
        for rule in config['rules']:
            if 'fund_codes' in rule:
                all_codes.update(rule['fund_codes'])
            elif 'fund_code' in rule:
                all_codes.add(rule['fund_code'])
        
        if not all_codes:
            logger.warning("é…ç½®ä¸­æ²¡æœ‰æ‰¾åˆ°åŸºé‡‘ä»£ç ")
            return None
        
        codes_list = list(all_codes)
        logger.info(f"ä»é…ç½®ä¸­æå–åˆ° {len(codes_list)} åªåŸºé‡‘ä»£ç ")
        
        # åˆ†åˆ«è·å–å¼€æ”¾å¼å’ŒæŒ‡æ•°åŸºé‡‘æ•°æ®
        open_data = self.get_specific_funds(codes_list, 'open')
        index_data = self.get_specific_funds(codes_list, 'index')
        
        # åˆå¹¶æ•°æ®
        combined_data = []
        if open_data is not None and not open_data.empty:
            combined_data.append(open_data)
        if index_data is not None and not index_data.empty:
            combined_data.append(index_data)
        
        if combined_data:
            result = pd.concat(combined_data, ignore_index=True)
            # å»é‡
            if 'åŸºé‡‘ä»£ç ' in result.columns:
                result = result.drop_duplicates(subset=['åŸºé‡‘ä»£ç '])
            logger.info(f"æœ€ç»ˆè·å–åˆ° {len(result)} åªåŸºé‡‘æ•°æ®")
            return result
        
        return None
    
    def get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        info = {}
        for cache_type in ['open_fund', 'index_fund']:
            info[cache_type] = {
                'cached': cache_type in self._cache,
                'valid': self._is_cache_valid(cache_type),
                'last_update': self._last_fetch_time.get(cache_type),
                'record_count': len(self._cache[cache_type]) if cache_type in self._cache else 0
            }
        return info


# åˆ›å»ºå…¨å±€å®ä¾‹
fetcher = SimpleFundDataFetcher()

# å…¼å®¹æ€§å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹
def get_open_fund_data() -> Optional[pd.DataFrame]:
    """è·å–æ‰€æœ‰å¼€æ”¾å¼åŸºé‡‘æ•°æ®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return fetcher.get_open_fund_data()

def get_index_fund_data() -> Optional[pd.DataFrame]:
    """è·å–æ‰€æœ‰æŒ‡æ•°åŸºé‡‘æ•°æ®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return fetcher.get_index_fund_data()

def get_specific_funds(codes: List[str], fund_type: str = 'open') -> Optional[pd.DataFrame]:
    """è·å–æŒ‡å®šåŸºé‡‘ä»£ç çš„æ•°æ®ï¼ˆå…¼å®¹æ€§å‡½æ•°ï¼‰"""
    return fetcher.get_specific_funds(codes, fund_type)


if __name__ == "__main__":
    # ç®€åŒ–çš„æµ‹è¯•ä»£ç 
    print("=== TickEye åŸºé‡‘æ•°æ®è·å–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰===")
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    
    # æµ‹è¯•è·å–å°‘é‡åŸºé‡‘
    print("\nğŸ“Š æµ‹è¯•è·å–æŒ‡å®šåŸºé‡‘...")
    test_codes = ["000001", "110022", "161725"]
    df = get_specific_funds(test_codes)
    
    if df is not None and not df.empty:
        print(f"æˆåŠŸè·å– {len(df)} åªåŸºé‡‘")
        print("å¯ç”¨åˆ—:", list(df.columns))
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print("\næ•°æ®ç¤ºä¾‹:")
        print(df.head(3))
    else:
        print("æœªè·å–åˆ°æ•°æ®")
    
    # æ˜¾ç¤ºç¼“å­˜ä¿¡æ¯
    print("\nğŸ’¾ ç¼“å­˜ä¿¡æ¯:")
    cache_info = fetcher.get_cache_info()
    for key, info in cache_info.items():
        print(f"  {key}: ç¼“å­˜={info['cached']}, æœ‰æ•ˆ={info['valid']}, è®°å½•æ•°={info['record_count']}")
